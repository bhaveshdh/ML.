{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensor in e:\\data\\lib\\site-packages (0.3.6)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Twisted in e:\\data\\lib\\site-packages (from tensor) (21.7.0)\n",
      "Requirement already satisfied: protobuf in e:\\data\\lib\\site-packages (from tensor) (3.19.1)\n",
      "Requirement already satisfied: PyYaml in e:\\data\\lib\\site-packages (from tensor) (5.3.1)\n",
      "Requirement already satisfied: construct in e:\\data\\lib\\site-packages (from tensor) (2.10.67)\n",
      "Requirement already satisfied: pysnmp in e:\\data\\lib\\site-packages (from tensor) (4.4.12)\n",
      "Requirement already satisfied: Automat>=0.8.0 in e:\\data\\lib\\site-packages (from Twisted->tensor) (20.2.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in e:\\data\\lib\\site-packages (from Twisted->tensor) (21.3.0)\n",
      "Requirement already satisfied: zope.interface>=4.4.2 in e:\\data\\lib\\site-packages (from Twisted->tensor) (5.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in e:\\data\\lib\\site-packages (from Twisted->tensor) (3.7.4.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\data\\lib\\site-packages (from Twisted->tensor) (20.3.0)\n",
      "Requirement already satisfied: constantly>=15.1 in e:\\data\\lib\\site-packages (from Twisted->tensor) (15.1.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in e:\\data\\lib\\site-packages (from Twisted->tensor) (21.0.0)\n",
      "Requirement already satisfied: twisted-iocpsupport~=1.0.0; platform_system == \"Windows\" in e:\\data\\lib\\site-packages (from Twisted->tensor) (1.0.2)\n",
      "Requirement already satisfied: pysmi in e:\\data\\lib\\site-packages (from pysnmp->tensor) (0.3.4)\n",
      "Requirement already satisfied: pyasn1>=0.2.3 in e:\\data\\lib\\site-packages (from pysnmp->tensor) (0.4.8)\n",
      "Requirement already satisfied: pycryptodomex in e:\\data\\lib\\site-packages (from pysnmp->tensor) (3.11.0)\n",
      "Requirement already satisfied: six in e:\\data\\lib\\site-packages (from Automat>=0.8.0->Twisted->tensor) (1.15.0)\n",
      "Requirement already satisfied: setuptools in e:\\data\\lib\\site-packages (from zope.interface>=4.4.2->Twisted->tensor) (50.3.1.post20201107)\n",
      "Requirement already satisfied: idna>=2.5 in e:\\data\\lib\\site-packages (from hyperlink>=17.1.1->Twisted->tensor) (2.10)\n",
      "Requirement already satisfied: ply in e:\\data\\lib\\site-packages (from pysmi->pysnmp->tensor) (3.11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tensor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "student_df=pd.read_csv('student.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maths</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maths  Physics  Chemistry  Result\n",
       "0     53       48         40     0.0\n",
       "1     41       10         49     0.0\n",
       "2     97       19          5     1.0\n",
       "3     53       56         20     1.0\n",
       "4     29       81         20     0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #suppress warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#convert imput to numpy arrays\n",
    "X = student_df.drop(columns=['Result'])\n",
    "y_label = student_df['Result'].values.reshape(X.shape[0], 1)\n",
    "#split data into train and test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y_label, test_size=0.2, random_state=2)\n",
    "#standardize the dataset\n",
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set is (799, 3)\n",
      "Shape of test set is (200, 3)\n",
      "Shape of train label is (799, 1)\n",
      "Shape of test labels is (200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    \n",
    "        \n",
    "    def __init__(self, layers=[3,15,1], learning_rate=0.001, iterations=100):\n",
    "        self.params = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.loss = []\n",
    "        self.sample_size = None\n",
    "        self.layers = layers\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "    \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Initialize the weights from a random normal distribution\n",
    "        '''\n",
    "        np.random.seed(1) # Seed the random number generator\n",
    "        self.params[\"W1\"] = np.random.randn(self.layers[0], self.layers[1]) \n",
    "        self.params['b1']  =np.random.randn(self.layers[1],)\n",
    "        self.params['W2'] = np.random.randn(self.layers[1],self.layers[2]) \n",
    "        self.params['b2'] = np.random.randn(self.layers[2],)\n",
    "    \n",
    "    def relu(self,Z):\n",
    "        '''\n",
    "        The ReLu activation function is to performs a threshold\n",
    "        operation to each input element where values less \n",
    "        than zero are set to zero.\n",
    "        '''\n",
    "        return np.maximum(0,Z)\n",
    "\n",
    "    def dRelu(self, x):\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1\n",
    "        return x\n",
    "\n",
    "    def eta(self, x):\n",
    "        ETA = 0.0000000001\n",
    "        return np.maximum(x, ETA)\n",
    "\n",
    "\n",
    "    def sigmoid(self,Z):\n",
    "        '''\n",
    "        The sigmoid function takes in real numbers in any range and \n",
    "        squashes it to a real-valued output between 0 and 1.\n",
    "        '''\n",
    "        return 1/(1+np.exp(-Z))\n",
    "\n",
    "    def entropy_loss(self,y, yhat):\n",
    "        nsample = len(y)\n",
    "        yhat_inv = 1.0 - yhat\n",
    "        y_inv = 1.0 - y\n",
    "        yhat = self.eta(yhat) ## clips value to avoid NaNs in log\n",
    "        yhat_inv = self.eta(yhat_inv) \n",
    "        loss = -1/nsample * (np.sum(np.multiply(np.log(yhat), y) + np.multiply((y_inv), np.log(yhat_inv))))\n",
    "        return loss\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        '''\n",
    "        Performs the forward propagation\n",
    "        '''\n",
    "        \n",
    "        Z1 = self.X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        yhat = self.sigmoid(Z2)\n",
    "        loss = self.entropy_loss(self.y,yhat)\n",
    "\n",
    "        # save calculated parameters     \n",
    "        self.params['Z1'] = Z1\n",
    "        self.params['Z2'] = Z2\n",
    "        self.params['A1'] = A1\n",
    "\n",
    "        return yhat,loss\n",
    "\n",
    "    def back_propagation(self,yhat):\n",
    "        '''\n",
    "        Computes the derivatives and update weights and bias according.\n",
    "        '''\n",
    "        y_inv = 1 - self.y\n",
    "        yhat_inv = 1 - yhat\n",
    "\n",
    "        dl_wrt_yhat = np.divide(y_inv, self.eta(yhat_inv)) - np.divide(self.y, self.eta(yhat))\n",
    "        dl_wrt_sig = yhat * (yhat_inv)\n",
    "        dl_wrt_z2 = dl_wrt_yhat * dl_wrt_sig\n",
    "\n",
    "        dl_wrt_A1 = dl_wrt_z2.dot(self.params['W2'].T)\n",
    "        dl_wrt_w2 = self.params['A1'].T.dot(dl_wrt_z2)\n",
    "        dl_wrt_b2 = np.sum(dl_wrt_z2, axis=0, keepdims=True)\n",
    "\n",
    "        dl_wrt_z1 = dl_wrt_A1 * self.dRelu(self.params['Z1'])\n",
    "        dl_wrt_w1 = self.X.T.dot(dl_wrt_z1)\n",
    "        dl_wrt_b1 = np.sum(dl_wrt_z1, axis=0, keepdims=True)\n",
    "\n",
    "        #update the weights and bias\n",
    "        self.params['W1'] = self.params['W1'] - self.learning_rate * dl_wrt_w1\n",
    "        self.params['W2'] = self.params['W2'] - self.learning_rate * dl_wrt_w2\n",
    "        self.params['b1'] = self.params['b1'] - self.learning_rate * dl_wrt_b1\n",
    "        self.params['b2'] = self.params['b2'] - self.learning_rate * dl_wrt_b2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Trains the neural network using the specified data and labels\n",
    "        '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.init_weights() #initialize weights and bias\n",
    "\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            yhat, loss = self.forward_propagation()\n",
    "            self.back_propagation(yhat)\n",
    "            self.loss.append(loss)\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predicts on a test data\n",
    "        '''\n",
    "        Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        pred = self.sigmoid(Z2)\n",
    "        return np.round(pred) \n",
    "\n",
    "    def acc(self, y, yhat):\n",
    "        '''\n",
    "        Calculates the accutacy between the predicted valuea and the truth labels\n",
    "        '''\n",
    "        acc = int(sum(y == yhat) / len(y) * 100)\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss curve\n",
    "        '''\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"logloss\")\n",
    "        plt.title(\"Loss curve for training\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNet() # create the NN model\n",
    "nn.fit(Xtrain, ytrain) #train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
